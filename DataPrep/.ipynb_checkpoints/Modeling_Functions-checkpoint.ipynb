{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions\n",
    "#Packages\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import wbgapi as wb\n",
    "import sklearn.preprocessing\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.covariance import MinCovDet\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "import scipy as scy\n",
    "import pandas as pd\n",
    "from time import time\n",
    "#from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso, PoissonRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import seaborn as sb\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scale_predictor_variables:\n",
    "    def __init__(self,X_train,y_train,pre_process,cv):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.pre_process = pre_process\n",
    "        self.cv = cv\n",
    "    def Plot_cross_validation_results(self):\n",
    "        pca = PCA()\n",
    "\n",
    "        X_reduced = pca.fit_transform(self.pre_process.fit_transform(self.X_train))\n",
    "                                \n",
    "\n",
    "        #define cross validation method\n",
    "        #cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "        regr = LinearRegression()\n",
    "        mse = []\n",
    "\n",
    "        # Calculate MSE with only the intercept\n",
    "        score = -1*model_selection.cross_val_score(regr,\n",
    "           np.ones((len(X_reduced),1)), self.y_train, cv=self.cv,\n",
    "           scoring='neg_mean_squared_error').mean()    \n",
    "        mse.append(score)\n",
    "\n",
    "        # Calculate MSE using cross-validation, adding one component at a time\n",
    "        for i in np.arange(1, 6):\n",
    "            score = -1*model_selection.cross_val_score(regr,\n",
    "               X_reduced[:,:i], self.y_train, cv=self.cv, scoring='neg_mean_squared_error').mean()\n",
    "            mse.append(score)\n",
    "    \n",
    "        # Plot cross-validation results    \n",
    "        plt.plot(mse)\n",
    "        plt.xlabel('Number of Principal Components')\n",
    "        plt.ylabel('MSE')\n",
    "        plt.title('CDD')\n",
    "        variance_ratio = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "        print(variance_ratio)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scoring:\n",
    "    def __init__(self,pre_process,X_train,y_train):\n",
    "        self.pre_process = pre_process\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    def Score(self):\n",
    "        ## data \n",
    "        ########################################################################\n",
    "        model_1 = RandomForestRegressor(max_depth=15,random_state=0) #aggregate the output of multiple models in decision trees\n",
    "        model_2 = LinearRegression(fit_intercept=True) \n",
    "        model_3 = Ridge(alpha=5) #adding an element k to the diagonal, to eliminate multicolinearity\n",
    "        model_4 = Lasso(alpha=10) #based on the principle of shrinkage - not only min of errors, but s.t. min of b√®ta's\n",
    "        model_5 = SVR(C=2.5, epsilon=0.5) #epsilon-insensitive tube creation = acceptable errors\n",
    "        model_6 = GradientBoostingRegressor(random_state=0) #iterative fitting of least-squares, each time improving - using the observation that decrease of MSE = negative gradient\n",
    "        model_7 = PoissonRegressor() #log-linear model!, assumes y has a Poisson distribution (generalized linear model)\n",
    "        \n",
    "        \n",
    "\n",
    "        MSE = []\n",
    "        R2 = []\n",
    "        for mymodels in [model_1,model_2,model_3,model_4,model_5,model_6,model_7]:\n",
    "            model_pipeline = Pipeline(steps=[('pre_processing',self.pre_process),('scaler', StandardScaler()),('reduce_dim', PCA()),\n",
    "                                 ('model', mymodels)\n",
    "                                 ])\n",
    "            model_pipeline.fit(self.X_train,self.y_train)\n",
    "            MSE.append(mean_squared_error(self.y_train,model_pipeline.predict(self.X_train))**0.5)\n",
    "            R2.append(r2_score(self.y_train,model_pipeline.predict(self.X_train)))\n",
    "    \n",
    "        print(np.round(MSE,2))   \n",
    "        print(np.round(R2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_select:\n",
    "    def __init__(self,X_train,y_train,X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "    def model_selection(self):\n",
    "        \"\"\"\n",
    "        hyperparameter tuning is performed using GridSearchCV\n",
    "        technique uses cross-validation when applying the default values of a 5-fold cross validation \n",
    "        as a means of splitting the training data into a training and validation sets.\n",
    "        model score is representen with the R-squared metrics\n",
    "        \"\"\"\n",
    "        models = []\n",
    "        models_1 = [\"Ridge\",\"Lasso\",\"LinearRegression\",\"PoissonRegressor\"]\n",
    "        models_2 = [\"RandomForestRegressor\",\"GradientBoostingRegressor\"]\n",
    "        model_3 = [\"SVR\"]\n",
    "        models += models_1 + models_2 + model_3\n",
    "        models_dictionary = {\"Ridge\":Ridge(),\"Lasso\":Lasso(),\"LinearRegression\":LinearRegression(fit_intercept=True),\n",
    "                             \"RandomForestRegressor\":RandomForestRegressor(random_state=0),\"GradientBoostingRegressor\":GradientBoostingRegressor(random_state=0),\n",
    "                            \"SVR\":SVR(epsilon=0.5),\"PoissonRegressor\":PoissonRegressor(max_iter=200)}\n",
    "        models_score = {}\n",
    "        \n",
    "        \n",
    "        # Tuning of parameters for regression by cross-validation\n",
    "                    # Number of cross valiations is 5\n",
    "        \n",
    "        for model in models:\n",
    "            if model in models_1:\n",
    "                \n",
    "                pipe = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('reduce_dim', PCA()),\n",
    "                ('regressor', models_dictionary[model])\n",
    "                ])\n",
    "                pipe = pipe.fit(self.X_train, self.y_train)\n",
    "                n_features_to_test = np.arange(1, 13)\n",
    "                alpha_to_test = 2.0**np.arange(-6, +6)\n",
    "            \n",
    "                if model == \"LinearRegression\":\n",
    "                    params = {'reduce_dim__n_components': n_features_to_test,\n",
    "                    'scaler' : [StandardScaler(), RobustScaler()]}\n",
    "                else:\n",
    "                    params = {'reduce_dim__n_components': n_features_to_test,\n",
    "                    'regressor__alpha': alpha_to_test,\n",
    "                    'scaler' : [StandardScaler(), RobustScaler()]}\n",
    "                gridsearch = GridSearchCV(pipe, params, verbose=1).fit(self.X_train, self.y_train)\n",
    "                \n",
    "            elif model in models_2:\n",
    "                \n",
    "                if model == \"RandomForestRegressor\":\n",
    "                  \n",
    "                    \n",
    "                    model_estimator =models_dictionary[model]\n",
    "                    params={'n_estimators':[20,30,40,60,80,100], 'max_depth': \n",
    "                    [5,10,15,20],'max_features':[2,5,8]}\n",
    "                    \n",
    "                     \n",
    "                else:\n",
    "                    model_estimator =  models_dictionary[model]\n",
    "                    \n",
    "                    params = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                    'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                    'n_estimators' : [20,30,40,60,80,100],\n",
    "                    'max_depth'    : [4,6,8,10]\n",
    "                     }\n",
    "                \n",
    "                gridsearch = GridSearchCV(estimator = model_estimator,param_grid = params,n_jobs=-1).fit(self.X_train, self.y_train)\n",
    "            else:\n",
    "                parameters = {'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9],'C': [1, 2.5, 5,7.5,10,15]}\n",
    "                gridsearch = GridSearchCV(models_dictionary[model], parameters).fit(self.X_train, self.y_train)\n",
    "             \n",
    "            print(\" Results from Grid Search:\",model)\n",
    "            print(\"\\n The best estimator across ALL searched params:\\n\",gridsearch.best_estimator_)\n",
    "            print(\"\\n The best score across ALL searched params:\\n\",gridsearch.best_score_)\n",
    "            print(\"\\n The best parameters across ALL searched params:\\n\",gridsearch.best_params_)\n",
    "            print('\\n Final score is: ', gridsearch.score(self.X_test, self.y_test))\n",
    "            print(\"\")\n",
    "            models_score[model] = gridsearch.score(self.X_test, self.y_test)\n",
    "        self.models_score = models_score\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
